Ground Truth of Glitch Tokens in Open-Source Large Language Models

In our ongoing efforts to enhance the reliability and performance of Large Language Models (LLMs), identifying and understanding anomalies in model behavior is crucial. This section presents the ground truth data for glitch tokens as detected in five prominent open-source LLMs. The glitches described herein were collected through comprehensive empirical studies designed to probe the models under various conditions and inputs.

Collection Methodology: The glitch tokens were identified using a repetive task to form input sequence here. 

Purpose of the Ground Truth Data: By analyzing these glitch tokens in the dataset, researchers and developers can gain insights into typical and atypical model behaviors, thereby improving both the design of new models and the diagnostic processes for existing ones. This dataset also serves as a foundational benchmark for evaluating the accuracy of glitch detection methodologies applied to LLMs. 
